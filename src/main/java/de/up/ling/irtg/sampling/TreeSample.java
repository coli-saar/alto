/*
 * To change this license header, choose License Headers in Project Properties.
 * To change this template file, choose Tools | Templates
 * and open the template in the editor.
 */
package de.up.ling.irtg.sampling;

import de.up.ling.tree.Tree;
import it.unimi.dsi.fastutil.doubles.DoubleArrayList;
import it.unimi.dsi.fastutil.doubles.DoubleList;
import java.util.ArrayList;
import java.util.List;
import org.apache.commons.math3.random.RandomGenerator;

/**
 * Represents all the trees drawn in a round of importance sampling along with
 * the necessary weights.
 * 
 * Note that all values need to be set externally.
 * 
 * @author christoph
 * @param <Type>
 */
public class TreeSample<Type> {
    /**
     * Contains the trees that have been drawn.
     */
    private final List<Tree<Type>> samplesDrawn = new ArrayList<>();
    
    /**
     * Contains the log of the proposal probability for each tree.
     */
    private final DoubleArrayList proposalWeight = new DoubleArrayList();
    
    /**
     * Contains the log of the target weight for each tree.
     */
    private final DoubleArrayList targetWeights = new DoubleArrayList();
    
    /**
     * Contains the log of the proposal probability summed up over all ways a
     * tree can be proposed.
     */
    private final DoubleArrayList sumProposalWeight = new DoubleArrayList();
    
    /**
     * Contains the weights that are generated by the different approaches to
     * self-normalization.
     */
    private final DoubleArrayList selfNormalizedWeight = new DoubleArrayList();
    
    /**
     * Adds a sample with all the weights set to 0.0. 
     * 
     * @param sample 
     */
    public void addSample(Tree<Type> sample) {
        this.samplesDrawn.add(sample);
        this.proposalWeight.add(0.0);
        this.targetWeights.add(0.0);
        this.sumProposalWeight.add(0.0);
        this.selfNormalizedWeight.add(0.0);
    }
    
    /**
     * Sets the value of the log of the sum of the proposal probabilities for
     * the given entry.
     * 
     * @param entry
     * @param amount 
     */
    public void setLogSumWeight(int entry, double amount) {
        this.sumProposalWeight.set(entry, amount);
    }
    
    /**
     * Sets the log of the proposal probability for the given entry.
     * 
     * @param entry
     * @param amount 
     */
    public void setLogPropWeight(int entry, double amount) {
        this.proposalWeight.set(entry, amount);
    }
    
    /**
     * Sets the log of the target weight for the given entry.
     * 
     * @param entry
     * @param amount
     */
    public void setLogTargetWeight(int entry, double amount) {
        this.targetWeights.set(entry, amount);
    }
    
    /**
     * Returns the log of the proposal probability for the given entry.
     * @param entry
     * @return 
     */
    public double getLogPropWeight(int entry) {
        return this.proposalWeight.get(entry);
    }
    
    /**
     * Returns the value of the log of the sum of the proposal probabilities for
     * the given entry.
     * 
     * @param entry
     * @return 
     */
    public double getLogSumWeight(int entry) {
        return this.sumProposalWeight.get(entry);
    }
    
    /**
     * Returns the log of the target weight for the given entry.
     * 
     * @param entry
     * @return 
     */
    public double getLogTargetWeight(int entry) {
        return this.targetWeights.get(entry);
    }
    
    /**
     * Returns the weight derived by the different self normalization approaches.
     * 
     * @param entry
     * @return 
     */
    public double getSelfNormalizedWeight(int entry) {
        return this.selfNormalizedWeight.get(entry);
    }
    
    /**
     * Returns the sample in the given position.
     * 
     * @param number
     * @return 
     */
    public Tree<Type> getSample(int number) {
        return this.samplesDrawn.get(number);
    }
    
    /**
     * Sets self normalized weight for each entry to the appropriate self normalized
     * value for each entry.
     * 
     * Deterministic decides whether we use the log proposal weight or the log
     * sum of proposals in order to compute the unnormalized importance weight.
     * 
     * @param deterministic 
     */
    public void expoNormalize(boolean deterministic){
        double sum = 0.0;
        double max = Double.NEGATIVE_INFINITY;
        for(int i=0;i<this.populationSize();++i) {
            double amount = this.getLogTargetWeight(i);
            amount -= deterministic ? this.getLogPropWeight(i) : this.getLogSumWeight(i);
            
            this.selfNormalizedWeight.set(i, amount);
            max = Math.max(max, amount);
        }
        
        for(int i=0;i<this.populationSize();++i) {
            double amount = Math.exp(this.getSelfNormalizedWeight(i)-max);
            if(!Double.isFinite(amount)) {
                amount = 0.0;
            }
            
            sum += amount;
            
            this.selfNormalizedWeight.set(i, amount);
        }
        
        for(int i=0;i<this.populationSize();++i) {
            this.selfNormalizedWeight.set(i, this.selfNormalizedWeight.get(i)/sum);
        }
    }

    /**
     * Returns the size of the underlying population.
     * 
     * @return 
     */
    public int populationSize() {
        return this.samplesDrawn.size();
    }
    
    /**
     * Resamples the trees so that they all have uniform weight.
     * 
     * First applies resampleWithNormalize.
     * 
     * @param rg
     * @param size
     * @param deterministic 
     */
    public void flatten(RandomGenerator rg, int size, boolean deterministic) {
        this.resampleWithNormalize(rg, size, deterministic);
        
        ArrayList<Tree<Type>> newChoices = new ArrayList<>();
        DoubleList newValues = new DoubleArrayList();
        
        double frac = 1.0 / size;
        for(int i=0;i<this.populationSize();++i) {
            int num = (int) (this.getSelfNormalizedWeight(i)*size);
            
            for(int k=0;k<num;++k) {
                newChoices.add(this.getSample(i));
                newValues.add(frac);
            }
        }
        
        this.samplesDrawn.clear();
        this.samplesDrawn.addAll(newChoices);
                
        this.selfNormalizedWeight.clear();
        this.selfNormalizedWeight.addAll(newValues);
    }
    
    /**
     * Resamples the trees.
     * 
     * Note that this makes the weight settings (except for self normalized)
     * invalid.
     * 
     * @param rg
     * @param size
     * @param deterministic 
     */
    public void resampleWithNormalize(RandomGenerator rg, int size, boolean deterministic) {
        this.expoNormalize(deterministic);
        this.resample(rg, size);
    }
    
    /**
     * Resamples the trees assuming that getSelfNormalized weight already returns the
     * correct values.
     * 
     * @param rg
     * @param size 
     */
    public void resample(RandomGenerator rg, int size) {
        double dsize = (double) size;
        
        List<Tree<Type>> newPop = new ArrayList<>();
        DoubleList newWeights = new DoubleArrayList();
        
        double sum = 0.0;
        for(int i=0;i<this.populationSize();++i) {
            double amount = Math.floor(dsize*this.getSelfNormalizedWeight(i)) / dsize;
            
            if(amount > 0.0) {
                newPop.add(this.getSample(i));
                newWeights.add(amount);
                
                sum += amount;
            }
        }
        
        double frac = 1.0 / dsize;
        while(sum < 1.0) {
            double d = rg.nextDouble();
            boolean done = false;
            
            for(int i=0;(i<this.populationSize() && (!done));++i) {
                d -= this.getSelfNormalizedWeight(i);
                
                if(d <= 0.0) {
                    done = true;
                    
                    newPop.add(this.getSample(i));
                    newWeights.add(frac);
                    
                    sum += frac;
                }
            }
        }
        
        this.samplesDrawn.clear();
        this.samplesDrawn.addAll(newPop);
        
        this.selfNormalizedWeight.clear();
        this.selfNormalizedWeight.addAll(newWeights);
    }

    @Override
    public String toString() {
        String s = System.lineSeparator();
        return "TreeSample"+ s + "samplesDrawn = " + samplesDrawn + s + "sampleWeights = " + proposalWeight;
    }    

    /**
     * Computes a 'self normalized' value  for adaption.
     * 
     * Here we do not need the values to sum to 1.0, so we simply use a maximum,
     * which is the maximum of original base and the largest importance weight
     * in the current sequence, to 'normalize' all importance weights. This is
     * intended to prevent underflow before we exponentiate. The resulting 
     * importance weights are the accessible by getSelfNormalizedWeight.
     * 
     * @param deterministic
     * @param originalBase
     * @return 
     */
    public double makeMaxBase(boolean deterministic, double originalBase) {
        double max = Double.NEGATIVE_INFINITY;
        
        for(int i=0;i<this.populationSize();++i){
            double amount = this.getLogTargetWeight(i);
            amount -= deterministic ? this.getLogPropWeight(i) : this.getLogSumWeight(i);
            
            max = Math.max(max, amount);
            this.selfNormalizedWeight.set(i, amount);
        }
        
        if(originalBase+3 >= max) {
            max = originalBase;
        }
        
        for(int i=0;i<this.populationSize();++i) {
            double d = Math.exp(this.selfNormalizedWeight.get(i)-max);
            if(!Double.isFinite(d)) {
                d = 0.0;
            }            
            this.selfNormalizedWeight.set(i, d);
        }
        
        return max;
    }

    /**
     * Clears out all the values stores in this sample.
     */
    public void clear() {
        this.proposalWeight.clear();
        this.samplesDrawn.clear();
        this.selfNormalizedWeight.clear();
        this.sumProposalWeight.clear();
        this.targetWeights.clear();
    }
}
